"""Run profile benchmarking and generate benchmarking graphics."""

import datetime
import pstats
import sys
import textwrap
from argparse import ArgumentParser
from io import StringIO
from pathlib import Path

import pandas as pd


def run_simple_benchmarking(prof_path: Path) -> pd.DataFrame:
    """Run a simplified benchmarking version.

    The function reads the contents of a ``.prof`` file (typically
    ``prof/combined.prof``) generated by running the profiling test suite and returns
    the profiling data as a standardised `pandas.DataFrame`.


    Args:
        prof_path: Path to the profiling output.
    """

    # Import the profile data, write the stats report to a StringIO and seek the start
    # to allow the data to be read. The print_stats() explicitly does not filter for
    # 'pyrealm' because the string can be found in virtual environment paths and leads
    # to inconsistent behaviour across platforms
    sio = StringIO()
    p = pstats.Stats(str(prof_path), stream=sio)
    p.sort_stats(pstats.SortKey.CUMULATIVE).print_stats()
    sio.seek(0)

    # Consume lines from the report to find the header row
    header_found = False
    while not header_found:
        header = sio.readline()
        if "ncalls" in header:
            header_found = True

    # Set replacement non-duplicated headers
    column_names = [
        "ncalls",
        "tottime",
        "tottime_percall",
        "cumtime",
        "cumtime_percall",
        "filename:lineno(function)",
    ]

    # Convert to a DataFrame using fixed width format
    df = pd.read_fwf(sio, engine="python", names=column_names, infer_nrows=10)

    # Add a timestamp from the file creation date
    m_time = datetime.datetime.fromtimestamp(prof_path.stat().st_mtime)
    df["timestamp"] = m_time.isoformat(timespec="seconds")

    return df


def run_simple_benchmarking_cli() -> None:
    """Run the simple benchmarking."""

    if run_simple_benchmarking_cli.__doc__ is not None:
        doc = "    " + run_simple_benchmarking_cli.__doc__
    else:
        doc = "Python in -OO mode"

    parser = ArgumentParser(
        description=textwrap.dedent(doc),
    )
    parser.add_argument(
        "prof_path",
        type=Path,
        help="Path to pytest-profiling output",
    )

    args = parser.parse_args()

    # Copy the profiling results to the current folder
    if not args.prof_path.exists():
        raise FileNotFoundError(f"Cannot find the profiling file at {args.prof_path}.")

    success = run_simple_benchmarking(prof_path=args.prof_path)

    if not success:
        print("Benchmarking failed.")
        sys.exit(1)

    print("Benchmarking passed.")
    sys.exit(0)


if __name__ == "__main__":
    run_simple_benchmarking_cli()
