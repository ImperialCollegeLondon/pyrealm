"""Run tests of the PModel.

These tests compare the pyrealm implementation to the outputs of the rpmodel
implementation.
"""

import json
import warnings
from contextlib import nullcontext as does_not_raise
from importlib import resources

import numpy as np
import pytest

# RPMODEL bugs
# rpmodel was using an incorrect parameterisation of the C4 ftemp kphio curve
# that is fixed but currently (1.2.0) an implementation error in the output checking
# means this still have to be skipped.

RPMODEL_C4_BUG = True


# ------------------------------------------
# Fixtures: inputs and expected values
# ------------------------------------------


@pytest.fixture(scope="module")
def values():
    """Fixture to load test inputs and expected rpmodel outputs from file."""

    datapath = (
        resources.files("pyrealm_build_data.rpmodel") / "test_outputs_rpmodel.json"
    )

    with open(str(datapath)) as infile:
        values = json.load(infile)

    # JSON contains nested dictionary of scalars and lists - convert
    # the lists to ndarrays, and use float to ensure that None --> np.nan
    # rather than the default output of dtype object.

    def lists_to_ndarray(d):
        for k, v in d.items():
            if isinstance(v, dict):
                lists_to_ndarray(v)
            elif isinstance(v, list):
                d[k] = np.array(v, dtype=float)
            else:
                pass

    lists_to_ndarray(values)

    return values


# ------------------------------------------
# Test structure
# The basic structure of these tests  is to use a pytest.mark.parameterise
# to pass in the variables to be passed to the function along with the key
# for sets of expected ouputs and any context managers.
#
# A separate R file is used to read in the same inputs to R and run them through
# rpmodel to generate the output file.
#
# TODO - should be able to group shared inputs (e.g. tc + patm) to recycle
#        parameterisation.
# ------------------------------------------

# ------------------------------------------
# Testing calc_density_h20 - temp + patm
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, patm, context_manager, expvals",
    [
        ("tc_sc", "patm_sc", does_not_raise(), "dens_h20_sc"),  # scalars
        ("tc_ar", "patm_sc", does_not_raise(), "dens_h20_mx"),  # mixed
        ("tc_ar", "patm_ar", does_not_raise(), "dens_h20_ar"),  # arrays
        ("tc_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_density_h2o(values, tc, patm, context_manager, expvals):
    """Test the calc_density_h2o function."""
    from pyrealm.core.water import calc_density_h2o

    with context_manager:
        ret = calc_density_h2o(tc=values[tc], patm=values[patm])
        if expvals is not None:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_ftemp_inst_rd - temp only but in Kelvin!
# ------------------------------------------


@pytest.mark.parametrize(
    "tk, expvars",
    [
        ("tk_sc", "ftemp_arrh_sc"),  # scalar
        ("tk_ar", "ftemp_arrh_ar"),  # array
    ],
)
def test_calc_ftemp_arrh(values, tk, expvars):
    """Test calc_ftemp_arrh outputs.

    Test against the pyrealm calculate_simple_arrhenius_factor function.
    """
    from pyrealm.pmodel import calculate_simple_arrhenius_factor

    ret = calculate_simple_arrhenius_factor(
        tk=values[tk], tk_ref=298.15, ha=values["KattgeKnorr_ha"]
    )
    assert np.allclose(ret, values[expvars])


# ------------------------------------------
# Testing calc_ftemp_inst_vcmax - temp only
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, expvars",
    [
        ("tc_sc", "ftemp_inst_vcmax_sc"),  # scalar
        ("tc_ar", "ftemp_inst_vcmax_ar"),  # array
    ],
)
def test_calc_ftemp_inst_vcmax(values, tc, expvars):
    """Test the calculation of values returned by calc_ftemp_inst_vcmax in rpmodel.

    This specific function was retired in favour of a more general modified arrhenius
    function, but check the predictions match to the rpmodel outputs for this component.
    """
    from pyrealm.constants import CoreConst, PModelConst
    from pyrealm.pmodel.functions import calculate_kattge_knorr_arrhenius_factor

    pmodel_const = PModelConst()
    core_const = CoreConst()

    cf = pmodel_const.arrhenius_vcmax["kattge_knorr"]

    # Calculate the arrhenius factor
    ret = calculate_kattge_knorr_arrhenius_factor(
        tk_leaf=values[tc] + core_const.k_CtoK,
        tk_ref=pmodel_const.plant_T_ref + core_const.k_CtoK,
        tc_growth=values[tc],  # This is an odd thing for rpmodel to do
        ha=cf["ha"],
        hd=cf["hd"],
        entropy_intercept=cf["entropy_intercept"],
        entropy_slope=cf["entropy_slope"],
        core_const=core_const,
    )

    assert np.allclose(ret, values[expvars])


# ------------------------------------------
# Testing calc_ftemp_kphio - temp only
# ------------------------------------------

# TODO - submit pull request to rpmodel with fix for this


@pytest.mark.parametrize(
    "tc, c4, expvars",
    [
        ("tc_sc", False, "ftemp_kphio_c3_sc"),  # scalar, C3
        ("tc_ar", False, "ftemp_kphio_c3_ar"),  # array, C3
        ("tc_sc", True, "ftemp_kphio_c4_sc"),  # scalar, C4
        ("tc_ar", True, "ftemp_kphio_c4_ar"),  # array, C4
    ],
)
def test_calc_ftemp_kphio(values, tc, c4, expvars):
    """Test the calc_ftemp_kphio values.

    This function in rpmodel has been replaced by the wider QuantumYield ABC framework
    but make sure the outputs still align.
    """
    from pyrealm.pmodel.pmodel_environment import PModelEnvironment
    from pyrealm.pmodel.quantum_yield import QuantumYieldTemperature

    # Only tc is used from this environment
    env = PModelEnvironment(tc=values[tc], patm=101325, vpd=820, co2=400)

    ret = QuantumYieldTemperature(env=env, use_c4=c4)

    # The QuantumYield class returns the actual kphio, not the correction factor, so
    # scale back to the correction factor
    assert np.allclose(ret.kphio / ret.reference_kphio, values[expvars])


# ------------------------------------------
# Testing calc_gammastar - temp + patm
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, patm, context_manager, expvals",
    [
        ("tc_sc", "patm_sc", does_not_raise(), "gammastar_sc"),  # scalars
        ("tc_ar", "patm_sc", does_not_raise(), "gammastar_mx"),  # mixed
        ("tc_ar", "patm_ar", does_not_raise(), "gammastar_ar"),  # arrays
        ("tc_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_gammastar(values, tc, patm, context_manager, expvals):
    """Test the calc_gammastar function."""
    from pyrealm.pmodel import calc_gammastar

    with context_manager:
        ret = calc_gammastar(tc=values[tc], patm=values[patm])
        if expvals is not None:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_kmm - temp + patm
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, patm, context_manager, expvals",
    [
        ("tc_sc", "patm_sc", does_not_raise(), "kmm_sc"),  # scalars
        ("tc_ar", "patm_sc", does_not_raise(), "kmm_mx"),  # mixed
        ("tc_ar", "patm_ar", does_not_raise(), "kmm_ar"),  # arrays
        ("tc_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_kmm(values, tc, patm, context_manager, expvals):
    """Test the calc_kmm function."""

    from pyrealm.pmodel import calc_kmm

    with context_manager:
        ret = calc_kmm(tc=values[tc], patm=values[patm])
        if expvals:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_soilmstress - soilm + meanalpha
# ------------------------------------------


@pytest.mark.parametrize(
    "soilm, meanalpha, context_manager, expvals",
    [
        ("soilm_sc", "meanalpha_sc", does_not_raise(), "soilmstress_sc"),  # scalars
        ("soilm_ar", "meanalpha_sc", does_not_raise(), "soilmstress_mx"),  # mixed
        ("soilm_ar", "meanalpha_ar", does_not_raise(), "soilmstress_ar"),  # arrays
        ("soilm_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_soilmstress_stocker(values, soilm, meanalpha, context_manager, expvals):
    """Test the calc_soilmstress_stocker function."""

    from pyrealm.pmodel import calc_soilmstress_stocker

    with context_manager:
        ret = calc_soilmstress_stocker(soilm=values[soilm], meanalpha=values[meanalpha])
        if expvals:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_viscosity_h2o - temp + patm
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, patm, context_manager, expvals",
    [
        ("tc_sc", "patm_sc", does_not_raise(), "viscosity_h2o_sc"),  # scalars
        ("tc_ar", "patm_sc", does_not_raise(), "viscosity_h2o_mx"),  # mixed
        ("tc_ar", "patm_ar", does_not_raise(), "viscosity_h2o_ar"),  # arrays
        ("tc_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_viscosity_h2o(values, tc, patm, context_manager, expvals):
    """Test the calc_viscosity_h2o function."""

    from pyrealm.pmodel import calc_viscosity_h2o

    with context_manager:
        ret = calc_viscosity_h2o(tc=values[tc], patm=values[patm])
        if expvals:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_patm - elev only
# ------------------------------------------


@pytest.mark.parametrize(
    "elev, expvals",
    [
        ("elev_sc", "patm_from_elev_sc"),  # scalars
        ("elev_ar", "patm_from_elev_ar"),  # arrays
    ],
)
def test_calc_patm(values, elev, expvals):
    """Test the calc_patm function."""

    from pyrealm.core.pressure import calc_patm

    ret = calc_patm(elv=values[elev])
    assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing calc_co2_to_ca - co2 + patm
# ------------------------------------------


@pytest.mark.parametrize(
    "co2, patm, context_manager, expvals",
    [
        ("co2_sc", "patm_sc", does_not_raise(), "ca_sc"),  # scalars
        ("co2_ar", "patm_sc", does_not_raise(), "ca_mx"),  # mixed
        ("co2_ar", "patm_ar", does_not_raise(), "ca_ar"),  # arrays
        ("co2_ar", "shape_error", pytest.raises(ValueError), None),  # shape mismatch
    ],
)
def test_calc_co2_to_ca(values, co2, patm, context_manager, expvals):
    """Test the calc_co2_to_ca function."""

    from pyrealm.pmodel import calc_co2_to_ca

    with context_manager:
        ret = calc_co2_to_ca(co2=values[co2], patm=values[patm])
        if expvals:
            assert np.allclose(ret, values[expvals])


# ------------------------------------------
# Testing CalcOptimalChi - vpd + internals kmm, gammastar, ns_star, ca
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, patm, co2, vpd, method, context_manager, expvalues",
    [
        (
            "tc_sc",
            "patm_sc",
            "co2_sc",
            "vpd_sc",
            "c4",
            does_not_raise(),
            "optchi_p14_sc_c4",
        ),  # scalar, c4
        (
            "tc_ar",
            "patm_sc",
            "co2_sc",
            "vpd_sc",
            "c4",
            does_not_raise(),
            "optchi_p14_mx_c4",
        ),  # scalar + arrays, c4
        (
            "tc_ar",
            "patm_ar",
            "co2_ar",
            "vpd_ar",
            "c4",
            does_not_raise(),
            "optchi_p14_ar_c4",
        ),  # arrays, c4
        (
            "shape_error",
            "patm_ar",
            "co2_ar",
            "vpd_ar",
            "c4",
            pytest.raises(ValueError),
            None,
        ),  # shape error, c4
        (
            "tc_sc",
            "patm_sc",
            "co2_sc",
            "vpd_sc",
            "prentice14",
            does_not_raise(),
            "optchi_p14_sc_c3",
        ),  # scalar, c3
        (
            "tc_ar",
            "patm_sc",
            "co2_sc",
            "vpd_sc",
            "prentice14",
            does_not_raise(),
            "optchi_p14_mx_c3",
        ),  # scalar + arrays, c3
        (
            "tc_ar",
            "patm_ar",
            "co2_ar",
            "vpd_ar",
            "prentice14",
            does_not_raise(),
            "optchi_p14_ar_c3",
        ),  # arrays, c3
        (
            "shape_error",
            "patm_ar",
            "co2_ar",
            "vpd_ar",
            "prentice14",
            pytest.raises(ValueError),
            None,
        ),  # shape error, c3
    ],
)
def test_optimal_chi(values, tc, patm, co2, vpd, method, context_manager, expvalues):
    """Test the CalcOptimalChi class."""

    from pyrealm.pmodel import PModelEnvironment
    from pyrealm.pmodel.optimal_chi import OPTIMAL_CHI_CLASS_REGISTRY

    with context_manager:
        env = PModelEnvironment(
            tc=values[tc], patm=values[patm], vpd=values[vpd], co2=values[co2]
        )

        OptChiClass = OPTIMAL_CHI_CLASS_REGISTRY[method]
        ret = OptChiClass(env)

        if expvalues is not None:
            expected = values[expvalues]
            assert np.allclose(ret.chi, expected["chi"])
            assert np.allclose(ret.mj, expected["mj"])
            assert np.allclose(ret.mc, expected["mc"])
            assert np.allclose(ret.mjoc, expected["mjoc"])


# ------------------------------------------
# Testing Jmax Limitation -  This has quite a few combinations:
# - c4
# - optchi - using both scalar and array inputs.
# - ftemp_kphio
# - Jmax limitation method
# - kphio - normally this varies with the pmodel input setup but imposing a
#       single value here (0.05) to simplify test suite.
# ------------------------------------------


@pytest.mark.parametrize("ftemp_kphio", [True, False], ids=["fkphio-on", "fkphio-off"])
@pytest.mark.parametrize(
    "jmax_method", ["wang17", "smith19", "none"], ids=["wang17", "smith19", "none"]
)
@pytest.mark.parametrize(
    "tc, patm, co2, vpd",
    [
        ("tc_sc", "patm_sc", "co2_sc", "vpd_sc"),  # scalar
        ("tc_ar", "patm_ar", "co2_ar", "vpd_ar"),  # arrays
    ],
    ids=["sc", "ar"],
)
@pytest.mark.parametrize("c4", [True, False], ids=["c4", "c3"])
def test_jmax_limitation(
    request, values, ftemp_kphio, jmax_method, tc, patm, co2, vpd, c4
):
    """Test the JMaxLimitation implementation class."""

    # This test is tricky because the internals of rpmodel and pyrealm differ
    # - rpmodel has a set of functions lue_vcmax_xxx, which return LUE and
    #   vcmax_unitiabs. These are adjusted at this stage in order to incorporate
    #   soil moisture effects in vcmax, which pyrealm does not do. So, we are
    #   comparing the Jmax limitation term, which isn't consistently outputted
    #   in the rpmodel functions (at least up to 1.2.2). So... instead we test
    #   LUE, which can be calculated locally to compare an equivalent prediction.
    #
    #  ftemp_kphio needs to know the original tc inputs to optchi
    # - these have all been synchronised so that anything with type 'mx' or 'ar'
    #   used the tc_ar input

    from pyrealm.pmodel import PModelEnvironment
    from pyrealm.pmodel.jmax_limitation import JMAX_LIMITATION_CLASS_REGISTRY
    from pyrealm.pmodel.optimal_chi import OPTIMAL_CHI_CLASS_REGISTRY
    from pyrealm.pmodel.quantum_yield import QuantumYieldTemperature

    oc_method = "c4" if c4 else "prentice14"

    # Optimal Chi
    env = PModelEnvironment(
        tc=values[tc], patm=values[patm], vpd=values[vpd], co2=values[co2]
    )

    if not ftemp_kphio:
        ftemp_kphio = 1.0
    else:
        kphio = QuantumYieldTemperature(env=env, use_c4=c4)
        ftemp_kphio = kphio.kphio / kphio.reference_kphio

    OptChiClass = OPTIMAL_CHI_CLASS_REGISTRY[oc_method]
    optchi = OptChiClass(env)

    jmax = JMAX_LIMITATION_CLASS_REGISTRY[jmax_method](optchi=optchi)

    # Find the expected values, extracting the combination from the request
    name = request.node.name
    name = name[(name.find("[") + 1) : -1]
    expected = values["jmax-" + name + "-sm-off"]

    # TODO - bug in rpmodel with scaling of Smith
    if jmax_method == "smith19":
        xf = 1 / 4
    else:
        xf = 1

    expected_lue = (
        (0.05 * ftemp_kphio) * optchi.mj * jmax.f_v * xf * env.core_const.k_c_molmass
    )
    assert np.allclose(expected_lue, expected["lue"], equal_nan=True)

    if jmax_method == "smith19":
        assert np.allclose(jmax.omega, expected["omega"], equal_nan=True)
        assert np.allclose(jmax.omega_star, expected["omega_star"], equal_nan=True)


# ------------------------------------------
# Testing PModelEnvironment class
# - double checking that the bundled calcs in here work as expected
# - test that the constraint issues a warning as expected.
# ------------------------------------------


@pytest.mark.parametrize(
    "tc, vpd, co2, patm, ca, kmm, gammastar, ns_star",
    [
        (
            "tc_sc",
            "vpd_sc",
            "co2_sc",
            "patm_sc",
            "ca_sc",
            "kmm_sc",
            "gammastar_sc",
            "ns_star_sc",
        ),
        (
            "tc_ar",
            "vpd_ar",
            "co2_ar",
            "patm_ar",
            "ca_ar",
            "kmm_ar",
            "gammastar_ar",
            "ns_star_ar",
        ),
    ],
    ids=["sc", "ar"],
)
def test_pmodelenvironment(values, tc, vpd, co2, patm, ca, kmm, gammastar, ns_star):
    """Test the PModelEnvironment class."""

    from pyrealm.pmodel import PModelEnvironment

    ret = PModelEnvironment(
        tc=values[tc], patm=values[patm], vpd=values[vpd], co2=values[co2]
    )

    assert np.allclose(ret.gammastar, values[gammastar])
    assert np.allclose(ret.ns_star, values[ns_star])
    assert np.allclose(ret.kmm, values[kmm])
    assert np.allclose(ret.ca, values[ca])


@pytest.mark.parametrize(
    argnames="inputs,context_manager",
    argvalues=[
        pytest.param(
            dict(tc=np.array([-15, 5, 10, 15, 20]), vpd=100000, co2=400, patm=101325),
            pytest.warns(UserWarning),
            id="warning",
        ),
        pytest.param(
            dict(tc=np.array([-15, 5, 10, 15, 20]), vpd=-1, co2=400, patm=101325),
            pytest.raises(ValueError),
            id="dewpoint_issues",
        ),
        pytest.param(
            dict(tc=np.array([-35, 5, 10, 15, 20]), vpd=1000, co2=400, patm=101325),
            pytest.raises(ValueError),
            id="too_cold",
        ),
    ],
)
def test_pmodelenvironment_exception(inputs, context_manager):
    """Test exceptions in creating the PModelEnvironment class."""

    from pyrealm.pmodel import PModelEnvironment

    with context_manager:
        _ = PModelEnvironment(**inputs)


# ------------------------------------------
# Testing PModel class - separate c3 and c4 tests
# - sc + ar inputs: tc, vpd, co2, patm (not testing elev)
# - +- soilmstress: soilm, meanalpha (but again assuming constant across ar inputs)
# - do_ftemp_kphio
# - luevcmax method

# For all tests
# - include fapar_sc and ppfd_sc (same irradiation everywhere)
# - hold kphio static
# ------------------------------------------


@pytest.fixture(scope="module")
def pmodelenv(values):
    """Fixture to create PModelEnvironments with scalar and array inputs.

    The mean growth temperature is also set to air temperature here to mirror the use of
    the implementation of Kattge Knorr Arrhenius scaling in rpmodel.
    """

    from pyrealm.pmodel import PModelEnvironment

    sc = PModelEnvironment(
        tc=values["tc_sc"],
        vpd=values["vpd_sc"],
        co2=values["co2_sc"],
        patm=values["patm_sc"],
        mean_growth_temperature=values["tc_sc"],
    )

    ar = PModelEnvironment(
        tc=values["tc_ar"],
        vpd=values["vpd_ar"],
        co2=values["co2_ar"],
        patm=values["patm_ar"],
        mean_growth_temperature=values["tc_ar"],
    )

    return {"sc": sc, "ar": ar}


@pytest.mark.parametrize("soilmstress", [False, True], ids=["sm-off", "sm-on"])
@pytest.mark.parametrize(
    "method_kphio", ["temperature", "fixed"], ids=["fkphio-on", "fkphio-off"]
)
@pytest.mark.parametrize(
    "luevcmax_method", ["wang17", "smith19", "none"], ids=["wang17", "smith19", "none"]
)
@pytest.mark.parametrize("environ", ["sc", "ar"], ids=["sc", "ar"])
def test_pmodel_class_c3(
    request, values, pmodelenv, soilmstress, method_kphio, luevcmax_method, environ
):
    """Test the PModel class for C3 plants."""

    from pyrealm.pmodel import PModel, calc_soilmstress_stocker

    # TODO - this is a bit odd as rpmodel embeds stocker soilm in model where in pyrealm
    #        it is only applied post-GPP calculation. Maybe disentangle these.
    if soilmstress:
        soilmstress = calc_soilmstress_stocker(
            values["soilm_sc"], values["meanalpha_sc"]
        )
    else:
        soilmstress = np.array([1.0])

    ret = PModel(
        pmodelenv[environ],
        method_kphio=method_kphio,
        method_jmaxlim=luevcmax_method,
        method_arrhenius="kattge_knorr",
        reference_kphio=0.05,
    )

    # Estimate productivity
    if environ == "sc":
        fapar = values["fapar_sc"]
        ppfd = values["ppfd_sc"]
    elif environ == "ar":
        fapar = values["fapar_ar"]
        ppfd = values["ppfd_ar"]

    ret.estimate_productivity(fapar=fapar, ppfd=ppfd)

    # Find the expected values, extracting the combination from the request
    name = request.node.name
    name = name[(name.find("[") + 1) : -1]
    expected = values[f"rpmodel-c3-{name}"]

    # Test chi and water use efficiency values
    # IWUE reported as µmol mol in pyrealm and Pa in rpmodel
    # rpmodel doesn't return LUE
    assert np.allclose(ret.optchi.chi, expected["chi"])
    assert np.allclose(ret.iwue * (ret.env.patm * 1e-6), expected["iwue"])

    # Test productivity values

    # As of rpmodel 1.2.2 there are scaling problems with Smith et al to do with
    # differences between phi_0 definitions and an actual error in Jmax calculation

    if "smith" in name:
        sc = 4
    else:
        sc = 1

    # Apply the soil moisture correction posthoc to pyrealm GPP, applied internally to
    # the rpmodel benchmark calculations.
    assert np.allclose(ret.gpp * soilmstress, sc * expected["gpp"], equal_nan=True)

    # Test exclusions:
    # - Also skip tests of jmax when no Jmax limitation is applied (none-) as the
    #   calculation in rpmodel leads to numerical instablity
    # - Also skip tests of Jmax for Smith et al - unresolved coding differences.

    if "sm-on" in name:
        warnings.warn(
            "Skipping jmax, vcmax,rd and gs testing when using soil moisture stress"
        )
        return

    if "none-fkphio-off-sm-off" in name or "none-fkphio-on-sm-off" in name:
        warnings.warn("Skipping Jmax test for cases with numerical instability")
    elif "smith" in name:
        warnings.warn("Skipping Jmax test for Smith due to calculation differences.")
    else:
        assert np.allclose(
            np.nan_to_num(ret.jmax), np.nan_to_num(expected["jmax"]), equal_nan=True
        )

    # pyrealm and pmodel do different things with jmax and vcmax
    assert np.allclose(ret.vcmax, sc * expected["vcmax"], equal_nan=True)
    assert np.allclose(ret.vcmax25, sc * expected["vcmax25"], equal_nan=True)

    # rd and g_s are calcualted using vcmax
    # TODO - tolerance turned up here to pass one of the Smith tests - remove later?

    assert np.allclose(ret.rd, sc * expected["rd"], equal_nan=True, atol=1e07)
    # Some algo issues with getting 0 and na in g_s
    # Fill na values with 0 in both inputs
    assert np.allclose(
        np.nan_to_num(ret.gs), sc * np.nan_to_num(expected["gs"]), atol=1e07
    )


# Testing PModel class with C4


@pytest.mark.parametrize("soilmstress", [False, True], ids=["sm-off", "sm-on"])
@pytest.mark.parametrize(
    "method_kphio", ["temperature", "fixed"], ids=["fkphio-on", "fkphio-off"]
)
@pytest.mark.parametrize("environ", ["sc", "ar"], ids=["sc", "ar"])
def test_pmodel_class_c4(
    request, values, pmodelenv, soilmstress, method_kphio, environ
):
    """Test the PModel class for C4 plants."""

    from pyrealm.pmodel import (
        PModel,
        PModelEnvironment,
        calc_soilmstress_stocker,
    )
    from pyrealm.pmodel.quantum_yield import QuantumYieldTemperature

    if soilmstress:
        soilmstress = calc_soilmstress_stocker(
            values["soilm_sc"], values["meanalpha_sc"]
        )
    else:
        soilmstress = np.array([1.0])

    # TODO bug in rpmodel 1.2.2 forces an odd downscaling of kphio when do_ftemp_kphio
    # is False, so the kf factor is calculated to scale the reference kphio back up to
    # match.

    if method_kphio == "temperature":
        kf = 1
    else:
        bug_env = PModelEnvironment(tc=15, patm=101325, vpd=800, co2=400)
        correction = QuantumYieldTemperature(
            env=bug_env, reference_kphio=0.05, use_c4=True
        )
        kf = correction.kphio / 0.05

    ret = PModel(
        pmodelenv[environ],
        method_kphio=method_kphio,
        method_jmaxlim="none",  # enforced in rpmodel.
        method_optchi="c4",
        method_arrhenius="kattge_knorr",
        reference_kphio=0.05 * kf,  # See note above
    )

    # Estimate productivity
    if environ == "sc":
        fapar = values["fapar_sc"]
        ppfd = values["ppfd_sc"]
    elif environ == "ar":
        fapar = values["fapar_ar"]
        ppfd = values["ppfd_ar"]

    ret.estimate_productivity(fapar=fapar, ppfd=ppfd)

    # Find the expected values, extracting the combination from the request
    name = request.node.name
    name = name[(name.find("[") + 1) : -1]
    expected = values["rpmodel-c4-" + name]

    # Test chi and water use efficiency values
    # IWUE reported as µmol mol in pyrealm and Pa in rpmodel
    # rpmodel doesn't return LUE
    assert np.allclose(ret.optchi.chi, expected["chi"])
    assert np.allclose(ret.iwue * (ret.env.patm * 1e-6), expected["iwue"])

    # Test productivity values
    assert np.allclose(ret.gpp * soilmstress, expected["gpp"], equal_nan=True)

    # Test exclusions:
    # - rpmodel adjusts vcmax and jmax when Stocker empirical soil moisture
    #   stress β(θ) is used and hence the predictions of g_s and rd.
    #   pyrealm.PModel _only_ adjusts the resulting LUE so skip tests of
    #   jmax, vcmax, rd and gs when sm is used.
    # - Also skip tests of jmax when no Jmax limitation is applied (none-) as the
    #   calculation in rpmodel leads to numerical instablity
    # - Also skip tests of Jmax for Smith et al - unresolved coding differences.

    if "sm-on" in name:
        warnings.warn(
            "Skipping jmax, vcmax,rd and gs testing when using soil moisture stress"
        )
        return

    # if 'none-fkphio-off-sm-off' in name or 'none-fkphio-on-sm-off' in name:
    warnings.warn("Skipping Jmax test for cases with numerical instability")
    # else:
    #     assert np.allclose(np.nan_to_num(ret.jmax),
    #                        np.nan_to_num(expected['jmax']), equal_nan=True)

    # pyrealm and pmodel do different things with jmax and vcmax
    assert np.allclose(ret.vcmax, expected["vcmax"], equal_nan=True)
    assert np.allclose(ret.vcmax25, expected["vcmax25"], equal_nan=True)

    # rd and g_s are calcualted using vcmax
    assert np.allclose(ret.rd, expected["rd"], equal_nan=True)

    # Some algo issues with getting 0 and na in g_s
    # Fill na values with 0 in both inputs
    warnings.warn("Skipping gs test for cases with numerical instability")
    # assert np.allclose(np.nan_to_num(ret.gs),
    #                 np.nan_to_num(expected['gs']))


def test_pmodel_summarise(capsys, values, pmodelenv):
    """Test the PModel summarize method."""

    from pyrealm.pmodel import PModel

    ret = PModel(pmodelenv["sc"], reference_kphio=0.05)

    # Test what comes back before estimate_productivity
    ret.summarize()

    out = capsys.readouterr().out

    assert all(["\n" + var in out for var in ("lue", "iwue")])
    assert not any(
        ["\n" + var in out for var in ("gpp", "vcmax", "vcmax25", "rd", "gs", "jmax")]
    )

    fapar = values["fapar_sc"]
    ppfd = values["ppfd_sc"]

    ret.estimate_productivity(fapar=fapar, ppfd=ppfd)

    # Test what comes back after estimate_productivity
    ret.summarize()

    out = capsys.readouterr().out

    assert all(
        [
            "\n" + var in out
            for var in ("lue", "iwue", "gpp", "vcmax", "vcmax25", "rd", "gs", "jmax")
        ]
    )


# Internal testing of functions


@pytest.mark.parametrize("tc", np.linspace(-5, 45, 5))
@pytest.mark.parametrize("theta", np.linspace(0, 0.8, 9))
@pytest.mark.parametrize(
    "variable_method, fixed_method, is_C4",
    [("lavergne20_c3", "prentice14", False), ("lavergne20_c4", "c4_no_gamma", True)],
)
def test_lavergne_equivalence(tc, theta, variable_method, fixed_method, is_C4):
    """Testing that the lavergne methods give equivalent predictions.

    Testing equivalence and functionality of lavergne methods for soil moisture impacts
    on the beta cost parameter - does taking the estimated beta from soil moisture
    effects following the lavergne methods give the same results as setting that beta in
    the equivalent non-soil moisture versions.
    """
    # Cannot do this test using N-D inputs because the PModelConst expect scalar values
    # for paramaterizing beta - you can't set an array of values. So, test combinations
    # of temperature and soil moisture.

    from pyrealm.constants import PModelConst
    from pyrealm.pmodel import PModel, PModelEnvironment

    env = PModelEnvironment(
        tc=tc,
        theta=theta,
        patm=np.array([101325]),
        vpd=np.array([100]),
        co2=np.array([400]),
    )

    # lavergne method
    mod_theta = PModel(env, method_optchi=variable_method)

    # get equivalent model for fixed beta
    if is_C4:
        const = PModelConst(beta_cost_ratio_c4=mod_theta.optchi.beta)
    else:
        const = PModelConst(beta_cost_ratio_prentice14=mod_theta.optchi.beta)

    env = PModelEnvironment(
        tc=tc,
        theta=theta,
        patm=np.array([101325]),
        vpd=np.array([100]),
        co2=np.array([400]),
        pmodel_const=const,
    )

    mod_fixed = PModel(env, method_optchi=fixed_method)

    assert np.allclose(mod_theta.optchi.chi, mod_fixed.optchi.chi)
    assert np.allclose(mod_theta.optchi.mj, mod_fixed.optchi.mj)
    assert np.allclose(mod_theta.optchi.mc, mod_fixed.optchi.mc)
    assert np.allclose(mod_theta.optchi.mjoc, mod_fixed.optchi.mjoc)
